<a href="index.md" name="top"><<返回目录</a>

# 网络爬虫基础

### 1. 概念
网络爬虫是通过网页的链接地址来寻找网页，从网站某一个页面（通常是首页）开始，读取网页的内容，找到在网页中的其它链接地址，然后通过这些链接地址寻找下一个网页，这样一直循环下去，直到把这个网站所有的网页都抓取完为止。如果把整个互联网当成一个网站，那么网络爬虫就可以用这个原理把互联网上所有的网页都抓取下来。

### 2. 用途 

网络爬虫可以做的事情很多，如以下列出：

* 搜索引擎
* 采集数据（金融、商品、竞品等）
* 广告过滤

其实就我们个人兴趣，学完爬虫我们可以看看当当网上哪种技术图书卖得比较火（销量、评论等信息）、看某个在线教育网站哪门网络课程做得比较成功、看双十一天猫的活动情况等等，只要我们感兴趣的数据，一般的话都可以爬取得到，不过有些网站比较狡猾，设置各种各样的反扒机制。总而言之，网络爬虫可以帮助我们做很多有趣的事情。


### 3. 原理
爬虫就是从种子URL开始，通过 HTTP 请求获取页面内容，并从页面内容中通过各种技术手段解析出更多的 URL，递归地请求获取页面的程序网络爬虫，总结其主要原理如下图：

![爬虫原理](img/yuanli1.png)

网络爬虫的基本工作流程如下：

1. 首先选取一部分精心挑选的种子URL；
2. 将这些URL放入待抓取URL队列；
3. 从待抓取URL队列中取出待抓取的URL，将URL对应的网页下载下来，存储进已下载网页库中。此外，将这些URL放进已抓取URL队列。
4. 分析已抓取URL队列中的URL，分析其中的其他URL，并且将URL放入待抓取URL队列，从而进入下一个循环。


### 4. 更新策略

互联网是实时变化的，具有很强的动态性。网页更新策略主要是决定何时更新之前已经下载过的页面。常见的更新策略又以下三种：

1.历史参考策略

顾名思义，根据页面以往的历史更新数据，预测该页面未来何时会发生变化。一般来说，是通过泊松过程进行建模进行预测。

2.用户体验策略   

尽管搜索引擎针对于某个查询条件能够返回数量巨大的结果，但是用户往往只关注前几页结果。因此，抓取系统可以优先更新那些现实在查询结果前几页中的网页，而后再更新那些后面的网页。这种更新策略也是需要用到历史信息的。用户体验策略保留网页的多个历史版本，并且根据过去每次内容变化对搜索质量的影响，得出一个平均值，用这个值作为决定何时重新抓取的依据。

3.聚类抽样策略

前面提到的两种更新策略都有一个前提：需要网页的历史信息。这样就存在两个问题：第一，系统要是为每个系统保存多个版本的历史信息，无疑增加了很多的系统负担；第二，要是新的网页完全没有历史信息，就无法确定更新策略。   
这种策略认为，网页具有很多属性，类似属性的网页，可以认为其更新频率也是类似的。要计算某一个类别网页的更新频率，只需要对这一类网页抽样，以他们的更新周期作为整个类别的更新周期。

### 5. Robots协议
[Robots协议](http://www.robotstxt.org/robotstxt.html)（Robots Exclusion Standard，网络爬虫排除标准）：    

*   作用：网站告知网络爬虫哪些页面可以爬取，哪些不行。   
*   形式：在网站根目录下的robots.txt文件。

Robots协议的基本语法：*代表所有，/代表根目录。例子：   

```
User-agent: *   
Disallow: /article/edit
Disallow: /discuss/write
Disallow: /discuss/edit
```

第1行中`User-agent: *`，是指所有的网络爬虫都需要遵守如下协议；   
第2行中`Disallow: /article/edit`，是指所有的网络爬虫都不允许访问`article/edit`下的内容，其他同理。   

点击查看：[百度的Robots协议](https://www.baidu.com/robots.txt)




 [返回顶部](#top)


